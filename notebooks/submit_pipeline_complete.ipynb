{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heading-1",
   "metadata": {},
   "source": [
    "# Personal Agendas Complete Pipeline with 4 Steps\n",
    "This notebook submits the complete Personal Agendas pipeline including:\n",
    "- Step 1: Data Preparation (Registration, Scan, Session)\n",
    "- Step 2: Neo4j Preparation (Visitors, Sessions, Relationships)\n",
    "- Step 3: Session Embedding\n",
    "- Step 4: Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AZURE ML PIPELINE COMPLETE\n",
      "============================================================\n",
      "Azure ML SDK Version: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]\n",
      "Current time: 2025-12-19T18:46:51.190994\n",
      "Target Azure ML env version: 10\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Azure ML imports\n",
    "from azure.ai.ml import MLClient, command, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Environment, AmlCompute\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "DEFAULT_PA_ENV_VERSION = 11\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "os.environ.setdefault(\"PA_ENV_VERSION\", str(DEFAULT_PA_ENV_VERSION))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AZURE ML PIPELINE COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "client_id = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\")\n",
    "workspace_name = os.getenv(\"AZUREML_WORKSPACE_NAME\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Azure ML SDK Version: {sys.version}\")\n",
    "print(f\"Current time: {datetime.now().isoformat()}\")\n",
    "print(f\"Target Azure ML env version: {os.getenv('PA_ENV_VERSION')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54e5c7b-43c7-4837-ba3c-2923132ccfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4eca3e-9a4b-4ed6-9bd6-60dbdc4d8bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j credentials configured\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Configure Neo4j credentials\n",
    "# Option 1: Load from .env file\n",
    "\n",
    "\n",
    "# Option 2: Set directly here (replace with your actual credentials)\n",
    "# Uncomment and update these lines:\n",
    "# os.environ[\"NEO4J_URI\"] = \"neo4j+s://your-instance.databases.neo4j.io\"\n",
    "# os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "# os.environ[\"NEO4J_PASSWORD\"] = \"your-password\"\n",
    "\n",
    "neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "if not all([neo4j_uri, neo4j_username, neo4j_password]):\n",
    "    print(\"WARNING: Neo4j credentials not found\")\n",
    "    print(\"Please set NEO4J_URI, NEO4J_USERNAME, and NEO4J_PASSWORD\")\n",
    "else:\n",
    "    print(\"Neo4j credentials configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fb439c-6344-4737-86d0-f8e1bcbffe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databricks / MLFLOW credentials configured\n"
     ]
    }
   ],
   "source": [
    "databricks_token = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "databricks_host = os.getenv(\"DATABRICKS_HOST\")\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow_registry_uri = os.getenv(\"MLFLOW_REGISTRY_URI\")\n",
    "mlflow_experiment_id = os.getenv(\"MLFLOW_EXPERIMENT_ID\")\n",
    "\n",
    "if not all([databricks_token, databricks_host, mlflow_tracking_uri, mlflow_registry_uri,mlflow_experiment_id]):\n",
    "    print(\"WARNING: Databricks / MLFLOW  credentials not found\")\n",
    "    print(\"Please set DATABRICKS_TOKEN, DATABRICKS_HOST, MLFLOW_TRACKING_URI, MLFLOW_REGISTRY_URI and MLFLOW_EXPERIMENT_ID\")\n",
    "else:\n",
    "    print(\"Databricks / MLFLOW credentials configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240a7996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required environment variables are present.\n"
     ]
    }
   ],
   "source": [
    "# Validate required environment variables (aligned with Key Vault secret map)\n",
    "from pprint import pprint\n",
    "\n",
    "required_env_vars = [\n",
    "    \"AZURE_CLIENT_ID\",\n",
    "    \"AZURE_CLIENT_SECRET\",\n",
    "    \"AZURE_TENANT_ID\",\n",
    "    \"SUBSCRIPTION_ID\",\n",
    "    \"RESOURCE_GROUP\",\n",
    "    \"AZUREML_WORKSPACE_NAME\",\n",
    "    \"KEYVAULT_NAME\",\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"AZURE_API_KEY\",\n",
    "    \"AZURE_ENDPOINT\",\n",
    "    \"AZURE_DEPLOYMENT\",\n",
    "    \"AZURE_API_VERSION\",\n",
    "    \"NEO4J_URI\",\n",
    "    \"NEO4J_USERNAME\",\n",
    "    \"NEO4J_PASSWORD\",\n",
    "    \"DATABRICKS_TOKEN\",\n",
    "    \"DATABRICKS_HOST\",\n",
    "    \"MLFLOW_TRACKING_URI\",\n",
    "    \"MLFLOW_REGISTRY_URI\",\n",
    "    \"MLFLOW_EXPERIMENT_ID\",\n",
    "    \"APPLICATIONINSIGHTS_CONNECTION_STRING\",\n",
    "    \"PA_ENV_VERSION\",\n",
    "]\n",
    "\n",
    "missing_env = [var for var in required_env_vars if not os.getenv(var)]\n",
    "if missing_env:\n",
    "    print(\"WARNING: The following environment variables are missing. Confirm notebooks/.env or Key Vault entries:\")\n",
    "    pprint(missing_env)\n",
    "else:\n",
    "    print(\"All required environment variables are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbb6f5a-936f-4674-b013-52b38c3e0af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propagating 40 environment variables to every step\n"
     ]
    }
   ],
   "source": [
    "# Environment variables propagated to every pipeline step\n",
    "current_dir = Path.cwd()\n",
    "project_root_for_env = current_dir.parent if current_dir.name == \"notebooks\" else current_dir\n",
    "pythonpath_entries = [\n",
    "    project_root_for_env.as_posix(),\n",
    "    (project_root_for_env / \"PA\").as_posix(),\n",
    "]\n",
    "path_separator = \":\" if os.name != \"nt\" else \";\"\n",
    "pythonpath_value = path_separator.join([entry for entry in pythonpath_entries if entry])\n",
    "keyvault_uri = None\n",
    "if os.getenv(\"KEYVAULT_NAME\"):\n",
    "    keyvault_uri = f\"https://{os.getenv('KEYVAULT_NAME')}.vault.azure.net/\"\n",
    "pa_env_version = os.getenv(\"PA_ENV_VERSION\", str(DEFAULT_PA_ENV_VERSION))\n",
    "otel_resource_detectors = os.getenv(\"OTEL_EXPERIMENTAL_RESOURCE_DETECTORS\", \"otel\")\n",
    "otel_service_name = os.getenv(\"OTEL_SERVICE_NAME\", \"pa-azureml-step\")\n",
    "env_vars_template = {\n",
    "    \"AZURE_CLIENT_ID\": os.getenv(\"AZURE_CLIENT_ID\"),\n",
    "    \"AZURE_CLIENT_SECRET\": os.getenv(\"AZURE_CLIENT_SECRET\"),\n",
    "    \"AZURE_TENANT_ID\": os.getenv(\"AZURE_TENANT_ID\"),\n",
    "    \"SUBSCRIPTION_ID\": os.getenv(\"SUBSCRIPTION_ID\"),\n",
    "    \"RESOURCE_GROUP\": os.getenv(\"RESOURCE_GROUP\"),\n",
    "    \"AZUREML_WORKSPACE_NAME\": os.getenv(\"AZUREML_WORKSPACE_NAME\"),\n",
    "    \"STORAGE_ACCOUNT_NAME\": \"strategicaistuksdev02\",\n",
    "    \"KEYVAULT_NAME\": os.getenv(\"KEYVAULT_NAME\"),\n",
    "    \"KEYVAULT_URI\": keyvault_uri,\n",
    "    \"OPENAI_API_KEY\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"AZURE_API_KEY\": os.getenv(\"AZURE_API_KEY\"),\n",
    "    \"AZURE_ENDPOINT\": os.getenv(\"AZURE_ENDPOINT\"),\n",
    "    \"AZURE_DEPLOYMENT\": os.getenv(\"AZURE_DEPLOYMENT\"),\n",
    "    \"AZURE_API_VERSION\": os.getenv(\"AZURE_API_VERSION\"),\n",
    "    \"AZURE_OPENAI_API_KEY\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"AZURE_OPENAI_ENDPOINT\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"AZURE_DEPLOYMENT_BATCH\": os.getenv(\"AZURE_DEPLOYMENT_BATCH\"),\n",
    "    \"AZURE_API_VERSION_BATCH\": os.getenv(\"AZURE_API_VERSION_BATCH\"),\n",
    "    \"NEO4J_URI\": os.getenv(\"NEO4J_URI\"),\n",
    "    \"NEO4J_USERNAME\": os.getenv(\"NEO4J_USERNAME\"),\n",
    "    \"NEO4J_PASSWORD\": os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    \"NEO4J_URI_DEV\": os.getenv(\"NEO4J_URI_DEV\"),\n",
    "    \"NEO4J_PASSWORD_DEV\": os.getenv(\"NEO4J_PASSWORD_DEV\"),\n",
    "    \"NEO4J_URI_TEST\": os.getenv(\"NEO4J_URI_TEST\"),\n",
    "    \"NEO4J_PASSWORD_TEST\": os.getenv(\"NEO4J_PASSWORD_TEST\"),\n",
    "    \"NEO4J_URI_PROD\": os.getenv(\"NEO4J_URI_PROD\"),\n",
    "    \"NEO4J_PASSWORD_PROD\": os.getenv(\"NEO4J_PASSWORD_PROD\"),\n",
    "    \"DATABRICKS_TOKEN\": os.getenv(\"DATABRICKS_TOKEN\"),\n",
    "    \"DATABRICKS_HOST\": os.getenv(\"DATABRICKS_HOST\"),\n",
    "    \"DATABRICKS_HOSTS\": os.getenv(\"DATABRICKS_HOSTS\"),\n",
    "    \"MLFLOW_TRACKING_URI\": os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "    \"MLFLOW_REGISTRY_URI\": os.getenv(\"MLFLOW_REGISTRY_URI\"),\n",
    "    \"MLFLOW_EXPERIMENT_ID\": os.getenv(\"MLFLOW_EXPERIMENT_ID\"),\n",
    "    \"APPLICATIONINSIGHTS_CONNECTION_STRING\": os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\"),\n",
    "    \"AZURE_APPINSIGHTS_CONNECTION_STRING\": os.getenv(\"AZURE_APPINSIGHTS_CONNECTION_STRING\"),\n",
    "    \"APPINSIGHTS_CONNECTION_STRING\": os.getenv(\"APPINSIGHTS_CONNECTION_STRING\"),\n",
    "    \"APPLICATIONINSIGHTS_AUTHENTICATION_MODE\": os.getenv(\"APPLICATIONINSIGHTS_AUTHENTICATION_MODE\"),\n",
    "    \"OTEL_EXPERIMENTAL_RESOURCE_DETECTORS\": otel_resource_detectors,\n",
    "    \"OTEL_SERVICE_NAME\": otel_service_name,\n",
    "    \"PA_ENV_VERSION\": pa_env_version,\n",
    "    \"PYTHONPATH\": pythonpath_value,\n",
    "}\n",
    "\n",
    "# Remove keys without values (Azure ML expects string values only)\n",
    "environment_variables = {key: value for key, value in env_vars_template.items() if value not in (None, \"\")}\n",
    "\n",
    "print(f\"Propagating {len(environment_variables)} environment variables to every step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace: strategicai-mlw-uks-dev-01\n"
     ]
    }
   ],
   "source": [
    "# Create ML Client\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=tenant_id,\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret\n",
    ")\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name\n",
    ")\n",
    "\n",
    "print(f\"Connected to workspace: {workspace_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from notebooks folder\n",
      "Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa\n",
      "‚úì PA directory found\n",
      "‚úì azureml_pipeline directory found\n",
      "‚úì Step 1 script found\n",
      "‚úì Step 2 script found\n",
      "‚úì Step 3 script found\n",
      "‚úì Step 4 script found\n",
      "‚úì config_ecomm.yaml found\n",
      "‚úì config_vet_lva.yaml found\n"
     ]
    }
   ],
   "source": [
    "# Verify project structure\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "    print(f\"Running from notebooks folder\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "    print(f\"Running from project root\")\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Check required directories\n",
    "pa_dir = project_root / \"PA\"\n",
    "if not pa_dir.exists():\n",
    "    print(f\"ERROR: PA directory not found at {pa_dir}\")\n",
    "else:\n",
    "    print(f\"‚úì PA directory found\")\n",
    "\n",
    "pipeline_dir = project_root / \"azureml_pipeline\"\n",
    "if not pipeline_dir.exists():\n",
    "    print(f\"Creating azureml_pipeline directory\")\n",
    "    pipeline_dir.mkdir(exist_ok=True)\n",
    "else:\n",
    "    print(f\"‚úì azureml_pipeline directory found\")\n",
    "\n",
    "# Check for all step scripts\n",
    "step_scripts = {\n",
    "    \"Step 1\": pipeline_dir / \"azureml_step1_data_prep.py\",\n",
    "    \"Step 2\": pipeline_dir / \"azureml_step2_neo4j_prep.py\",\n",
    "    \"Step 3\": pipeline_dir / \"azureml_step3_session_embedding.py\",\n",
    "    \"Step 4\": pipeline_dir / \"azureml_step4_recommendations.py\"\n",
    "}\n",
    "\n",
    "for step_name, script_path in step_scripts.items():\n",
    "    if script_path.exists():\n",
    "        print(f\"‚úì {step_name} script found\")\n",
    "    else:\n",
    "        print(f\"WARNING: {step_name} script not found at {script_path}\")\n",
    "\n",
    "# Check config files\n",
    "config_vet = pa_dir / \"config\" / \"config_vet_lva.yaml\"\n",
    "config_ecomm = pa_dir / \"config\" / \"config_ecomm.yaml\"\n",
    "\n",
    "if config_ecomm.exists():\n",
    "    print(f\"‚úì config_ecomm.yaml found\")\n",
    "if config_vet.exists():\n",
    "    print(f\"‚úì config_vet_lva.yaml found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup (restored auto-version logic)\n",
    "dependencies_dir = Path(\"./env\")\n",
    "if not dependencies_dir.exists():\n",
    "    notebooks_env = project_root / \"notebooks\" / \"env\"\n",
    "    repo_env = project_root / \"env\"\n",
    "    if notebooks_env.exists():\n",
    "        dependencies_dir = notebooks_env\n",
    "    elif repo_env.exists():\n",
    "        dependencies_dir = repo_env\n",
    "custom_env_name = \"pa-env\"\n",
    "requested_version_raw = os.getenv(\"PA_ENV_VERSION\", str(DEFAULT_PA_ENV_VERSION))\n",
    "try:\n",
    "    requested_env_version = int(requested_version_raw)\n",
    "except ValueError:\n",
    "    print(\n",
    "        f\"WARNING: Invalid PA_ENV_VERSION '{requested_version_raw}'. Will auto-increment from existing versions.\")\n",
    "    requested_env_version = None\n",
    "\n",
    "existing_envs = {}\n",
    "existing_versions = []\n",
    "try:\n",
    "    for env in ml_client.environments.list(name=custom_env_name):\n",
    "        version_str = str(env.version)\n",
    "        if version_str.isdigit():\n",
    "            version_int = int(version_str)\n",
    "            existing_versions.append(version_int)\n",
    "            existing_envs[version_int] = env\n",
    "except Exception as exc:\n",
    "    print(f\"Warning: unable to enumerate existing environments ({exc})\")\n",
    "\n",
    "latest_version = max(existing_versions) if existing_versions else None\n",
    "\n",
    "conda_file = dependencies_dir / \"conda.yaml\"\n",
    "if not conda_file.exists():\n",
    "    print(f\"WARNING: conda.yaml not found at {conda_file}\")\n",
    "    print(\"Using default conda configuration\")\n",
    "\n",
    "if requested_env_version is not None and requested_env_version in existing_envs:\n",
    "    job_env = existing_envs[requested_env_version]\n",
    "    print(f\"Using existing environment: {job_env.name}:{job_env.version}\")\n",
    "elif latest_version is not None and requested_env_version == latest_version:\n",
    "    job_env = existing_envs[latest_version]\n",
    "    print(\n",
    "        f\"Notebook version matches latest workspace version ({latest_version}); reusing environment {job_env.name}:{job_env.version}\")\n",
    "else:\n",
    "    version_to_create = (\n",
    "        requested_env_version\n",
    "        if requested_env_version is not None\n",
    "        else (latest_version + 1 if latest_version is not None else 1)\n",
    "    )\n",
    "\n",
    "    if latest_version is not None and version_to_create <= latest_version:\n",
    "        version_to_create = latest_version + 1\n",
    "        print(f\"Requested version already exists or is older. Incrementing to {version_to_create}.\")\n",
    "\n",
    "    print(f\"Creating environment version {version_to_create} for {custom_env_name}\")\n",
    "    environment_kwargs = {\n",
    "        \"name\": custom_env_name,\n",
    "        \"version\": str(version_to_create),\n",
    "        \"description\": \"Environment for Personal Agendas pipeline with Neo4j and embeddings\",\n",
    "        \"conda_file\": str(conda_file) if conda_file.exists() else None,\n",
    "        \"image\": \"mcr.microsoft.com/azureml/openmpi5.0-ubuntu24.04:20250601.v1\",\n",
    "    }\n",
    "\n",
    "    job_env = Environment(**environment_kwargs)\n",
    "    job_env = ml_client.environments.create_or_update(job_env)\n",
    "    print(f\"Created environment: {job_env.name}:{job_env.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested PA_ENV_VERSION 10 is lower than supported minimum 12. Forcing 12.\n",
      "Pinned 59 pip dependencies into /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa/azureml_pipeline/pa_env_v12_conda.yaml\n",
      "Created environment: pa-env:12\n",
      "Pipeline steps will use environment version 12\n"
     ]
    }
   ],
   "source": [
    "# Define INCREMENTAL versions of the components (optional)\n",
    "session_embedding_component_incremental = command(\n",
    "    name=\"session_embedding_incremental\",\n",
    "    display_name=\"Step 3: Session Embedding (Incremental)\",\n",
    "    description=\"Generate embeddings only for new sessions without embeddings\",\n",
    "    inputs={\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "        \"neo4j_ready\": Input(type=\"uri_folder\", optional=True),\n",
    "        \"input_registration\": Input(type=\"uri_folder\"),\n",
    "        \"input_scan\": Input(type=\"uri_folder\"),\n",
    "        \"input_session\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step3_session_embedding.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_registration ${{inputs.input_registration}} \\\n",
    "        --input_scan ${{inputs.input_scan}} \\\n",
    "        --input_session ${{inputs.input_session}} \\\n",
    "        --incremental true \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables=environment_variables,\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation Component\n",
    "data_preparation_component = command(\n",
    "    name=\"data_preparation\",\n",
    "    display_name=\"Step 1: Data Preparation\",\n",
    "    description=\"Process registration, scan, and session data\",\n",
    "    inputs={\n",
    "        \"input_uri\": Input(type=\"uri_folder\"),\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "        \"incremental\": Input(type=\"string\", default=\"false\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"registration_output\": Output(type=\"uri_folder\"),\n",
    "        \"scan_output\": Output(type=\"uri_folder\"),\n",
    "        \"session_output\": Output(type=\"uri_folder\"),\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step1_data_prep.py \\\\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\\\n",
    "        --input_uri ${{inputs.input_uri}} \\\\\n",
    "        --incremental ${{inputs.incremental}} \\\\\n",
    "        --output_registration ${{outputs.registration_output}} \\\\\n",
    "        --output_scan ${{outputs.scan_output}} \\\\\n",
    "        --output_session ${{outputs.session_output}} \\\\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables=environment_variables,\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Step 2 component defined\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Neo4j Preparation Component\n",
    "\n",
    "neo4j_preparation_component = command(\n",
    "    name=\"neo4j_preparation\",\n",
    "    display_name=\"Step 2: Neo4J Preparation\",\n",
    "    description=\"Upload data to Neo4j database\",\n",
    "    inputs={\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "        \"input_registration\": Input(type=\"uri_folder\"),\n",
    "        \"input_scan\": Input(type=\"uri_folder\"),\n",
    "        \"input_session\": Input(type=\"uri_folder\"),\n",
    "        \"incremental\": Input(type=\"string\", default=\"false\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step2_neo4j_prep.py \\\\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\\\n",
    "        --input_registration ${{inputs.input_registration}} \\\\\n",
    "        --input_scan ${{inputs.input_scan}} \\\\\n",
    "        --input_session ${{inputs.input_session}} \\\\\n",
    "        --incremental ${{inputs.incremental}} \\\\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables=environment_variables,\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Step 2 component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Step 3 component defined\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Session Embedding Component\n",
    "session_embedding_component = command(\n",
    "    name=\"session_embedding\",\n",
    "    display_name=\"Step 3: Session Embedding\",\n",
    "    description=\"Generate and store text embeddings for session nodes in Neo4j\",\n",
    "    inputs={\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "        \"neo4j_ready\": Input(type=\"uri_folder\", optional=True),\n",
    "        \"input_registration\": Input(type=\"uri_folder\"),\n",
    "        \"input_scan\": Input(type=\"uri_folder\"),\n",
    "        \"input_session\": Input(type=\"uri_folder\"),\n",
    "        \"incremental\": Input(type=\"string\", default=\"false\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step3_session_embedding.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_registration ${{inputs.input_registration}} \\\n",
    "        --input_scan ${{inputs.input_scan}} \\\n",
    "        --input_session ${{inputs.input_session}} \\\n",
    "        --incremental ${{inputs.incremental}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables=environment_variables,\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Step 3 component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Step 4 component defined\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Recommendations Component\n",
    "recommendations_component = command(\n",
    "    name=\"recommendations\",\n",
    "    display_name=\"Step 4: Recommendations\",\n",
    "    description=\"Generate session recommendations for visitors\",\n",
    "    inputs={\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "        \"embeddings_ready\": Input(type=\"uri_folder\", optional=True),\n",
    "        \"input_registration\": Input(type=\"uri_folder\"),\n",
    "        \"input_scan\": Input(type=\"uri_folder\"),\n",
    "        \"input_session\": Input(type=\"uri_folder\"),\n",
    "        \"incremental\": Input(type=\"string\", default=\"false\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step4_recommendations.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_registration ${{inputs.input_registration}} \\\n",
    "        --input_scan ${{inputs.input_scan}} \\\n",
    "        --input_session ${{inputs.input_session}} \\\n",
    "        --incremental ${{inputs.incremental}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables=environment_variables,\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Step 4 component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Complete pipeline defined\n"
     ]
    }
   ],
   "source": [
    "# Define the complete pipeline\n",
    "@pipeline(\n",
    "    compute=\"cpu-cluster\",\n",
    "    description=\"Complete Personal Agendas pipeline with 4 steps\",\n",
    ")\n",
    "def personal_agendas_complete_pipeline(\n",
    "    pipeline_input_data: Input,\n",
    "    pipeline_config_type: str = \"ecomm\",\n",
    "    pipeline_incremental: str = \"false\"\n",
    "):\n",
    "    \"\"\"Complete Personal Agendas pipeline.\"\"\"\n",
    "    \n",
    "    # Step 1: Data Preparation\n",
    "    step1 = data_preparation_component(\n",
    "        input_uri=pipeline_input_data,\n",
    "        config_type=pipeline_config_type,\n",
    "        incremental=pipeline_incremental\n",
    "    )\n",
    "    step1.name = \"step1_data_preparation\"\n",
    "    \n",
    "    # Step 2: Neo4J Preparation - uses outputs from Step 1\n",
    "    step2 = neo4j_preparation_component(\n",
    "        config_type=pipeline_config_type,\n",
    "        input_registration=step1.outputs.registration_output,\n",
    "        input_scan=step1.outputs.scan_output,\n",
    "        input_session=step1.outputs.session_output,\n",
    "        incremental=pipeline_incremental\n",
    "    )\n",
    "    step2.name = \"step2_neo4j_preparation\"\n",
    "    \n",
    "    # Step 3: Session Embedding - runs after Neo4j data is loaded\n",
    "    # It stages Step 1 artifacts for any processors that expect files on disk\n",
    "    step3 = session_embedding_component(\n",
    "        config_type=pipeline_config_type,\n",
    "        neo4j_ready=step2.outputs.metadata_output,\n",
    "        input_registration=step1.outputs.registration_output,\n",
    "        input_scan=step1.outputs.scan_output,\n",
    "        input_session=step1.outputs.session_output,\n",
    "        incremental=pipeline_incremental\n",
    "    )\n",
    "    step3.name = \"step3_session_embedding\"\n",
    "    \n",
    "    # Step 4: Recommendations\n",
    "    step4 = recommendations_component(\n",
    "        config_type=pipeline_config_type,\n",
    "        embeddings_ready=step3.outputs.metadata_output,\n",
    "        input_registration=step1.outputs.registration_output,\n",
    "        input_scan=step1.outputs.scan_output,\n",
    "        input_session=step1.outputs.session_output,\n",
    "        incremental=pipeline_incremental\n",
    "    )\n",
    "    step4.name = \"step4_recommendations\"\n",
    "    \n",
    "    # Return all outputs\n",
    "    return {\n",
    "        \"registration_data\": step1.outputs.registration_output,\n",
    "        \"scan_data\": step1.outputs.scan_output,\n",
    "        \"session_data\": step1.outputs.session_output,\n",
    "        \"step1_metadata\": step1.outputs.metadata_output,\n",
    "        \"neo4j_metadata\": step2.outputs.metadata_output,\n",
    "        \"embedding_metadata\": step3.outputs.metadata_output,\n",
    "        \"recommendations_metadata\": step4.outputs.metadata_output\n",
    "    }\n",
    "\n",
    "print(\"‚úì Complete pipeline defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data URI: azureml://subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01/datastores/landing_pa/paths/landing/azureml/\n"
     ]
    }
   ],
   "source": [
    "# Configure input data URI\n",
    "input_data_uri = f\"azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace_name}/datastores/landing_pa/paths/landing/azureml/\"\n",
    "\n",
    "print(f\"Input data URI: {input_data_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pipeline instance created\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline instance\n",
    "pipeline_incremental_value = \"false\"\n",
    "pipeline_job = personal_agendas_complete_pipeline(\n",
    "    pipeline_input_data=Input(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=input_data_uri\n",
    "    ),\n",
    "    pipeline_config_type=\"vet_lva\",  # or \"vet\"\n",
    "    pipeline_incremental=pipeline_incremental_value\n",
    ")\n",
    "\n",
    "# Configure pipeline metadata\n",
    "pipeline_job.display_name = \"Personal Agendas Complete Pipeline - LVA\"\n",
    "pipeline_job.tags = {\n",
    "    \"project\": \"personal_agendas\",\n",
    "    \"event_type\": \"lva\",\n",
    "    \"environment\": \"prod\",\n",
    "    \"includes_neo4j\": \"true\",\n",
    "    \"includes_embeddings\": \"true\",\n",
    "    \"includes_recommendations\": \"true\",\n",
    "    \"incremental\": pipeline_incremental_value,\n",
    "    \"step_count\": \"4\",\n",
    "    \"complete_pipeline\": \"true\"\n",
    "}\n",
    "pipeline_job.experiment_name = \"personal_agendas_complete_experiment\"\n",
    "\n",
    "print(\"‚úì Pipeline instance created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting pipeline...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading azure_ml_pipelines_pa (2.61 MBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2607062/2607062 [00:01<00:00, 1750479.38it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading azure_ml_pipelines_pa (2.61 MBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2605010/2605010 [00:01<00:00, 1838004.89it/s]\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pipeline submitted successfully!\n",
      "\n",
      "Pipeline Details:\n",
      "  Name: quirky_peach_6xd1z4p9w8\n",
      "  Display Name: Personal Agendas Complete Pipeline - LVA\n",
      "  Status: NotStarted\n",
      "  Experiment: personal_agendas_complete_experiment\n",
      "\n",
      "üîó View pipeline in Azure ML Studio:\n",
      "  https://ml.azure.com/runs/quirky_peach_6xd1z4p9w8?wsid=/subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01&tid=3540e7dc-31b3-4057-9e31-43e9fe938179\n"
     ]
    }
   ],
   "source": [
    "# Submit the pipeline\n",
    "print(\"\\nSubmitting pipeline...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Submit the pipeline job\n",
    "    pipeline_run = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    \n",
    "    print(f\"‚úì Pipeline submitted successfully!\")\n",
    "    print(f\"\\nPipeline Details:\")\n",
    "    print(f\"  Name: {pipeline_run.name}\")\n",
    "    print(f\"  Display Name: {pipeline_run.display_name}\")\n",
    "    print(f\"  Status: {pipeline_run.status}\")\n",
    "    print(f\"  Experiment: {pipeline_run.experiment_name}\")\n",
    "    print(f\"\\nüîó View pipeline in Azure ML Studio:\")\n",
    "    print(f\"  {pipeline_run.studio_url}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error submitting pipeline: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monitoring pipeline progress...\n",
      "(Press Ctrl+C to stop monitoring)\n",
      "\n",
      "[17:24:54] Status: NotStarted (waiting...)"
     ]
    }
   ],
   "source": [
    "# Optional: Monitor pipeline progress\n",
    "import time\n",
    "\n",
    "print(\"\\nMonitoring pipeline progress...\")\n",
    "print(\"(Press Ctrl+C to stop monitoring)\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get the latest status\n",
    "        job = ml_client.jobs.get(pipeline_run.name)\n",
    "        \n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] Status: {job.status}\", end=\"\")\n",
    "        \n",
    "        if job.status in [\"Completed\", \"Failed\", \"Canceled\"]:\n",
    "            print(f\"\\n\\nPipeline {job.status}!\")\n",
    "            if job.status == \"Failed\":\n",
    "                print(\"Check the logs in Azure ML Studio for error details.\")\n",
    "            break\n",
    "        \n",
    "        print(\" (waiting...)\", end=\"\\r\")\n",
    "        time.sleep(30)  # Check every 30 seconds\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nMonitoring stopped. Pipeline continues running in Azure ML.\")\n",
    "    print(f\"Check status at: {pipeline_run.studio_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown-1",
   "metadata": {},
   "source": [
    "## Pipeline Summary\n",
    "\n",
    "This notebook submits a complete 4-step Personal Agendas pipeline:\n",
    "\n",
    "1. **Data Preparation**: Processes registration, scan, and session data\n",
    "2. **Neo4j Preparation**: Loads data into Neo4j and creates relationships\n",
    "3. **Session Embedding**: Generates embeddings for sessions\n",
    "4. **Recommendations**: Generates personalized session recommendations\n",
    "\n",
    "### Key Features:\n",
    "- Fully generic and configurable (works with both `ecomm` and `vet` configurations)\n",
    "- Proper data flow between steps\n",
    "- Neo4j integration with secure credential management\n",
    "- Incremental processing support (can be enabled per step)\n",
    "- Complete error handling and logging\n",
    "\n",
    "### Next Steps:\n",
    "1. Monitor the pipeline execution in Azure ML Studio\n",
    "2. Check the output metadata for each step\n",
    "3. Verify recommendations are generated in Neo4j\n",
    "4. Download the recommendations output file for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad8e35-7a49-4b38-8f27-17f992fdb6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571aadc3-5d61-4b3c-829d-e65205f0ef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
